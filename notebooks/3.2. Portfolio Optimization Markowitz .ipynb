{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization\n",
    "Modern portfolio theory is also known as mean-variance optimization.\n",
    "\n",
    "One fundamental assumption is that returns are **normally distributed**.\n",
    "\n",
    "We will focus on:\n",
    "* Normality test: Mean Variance Portfolio Theory (MPT) and Capital Asset Pricing Model (CAPM)\n",
    "* Portfolio optimization\n",
    "* Bayesian statistics\n",
    "* Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Portfolio theory***\n",
    "\n",
    "Stock returns are assumed to be normally distributed. Investment decissions are then based on expected mean return as well as variance of returns. \n",
    "\n",
    "***CAPM***\n",
    "\n",
    "Again, when stock returns are normally distributed, prices of single stockscan be elegantly expressed in linear relationship to a broad market index;the relationship is generally expressed by a measure for the co-movement of a single stock with the market called beta or $\\beta$.\n",
    "\n",
    "***Efficient Markets Hypothesis***\n",
    "\n",
    "An efficient market is a market where prices reflect all available information, where 'all' can be defined more narrowly or more widely (e.g. as in 'all publicly available information vs including also only privately available information'). If this hypothesis holds true, then stock prices fluctuate randomly and returns are normally distributed.\n",
    "\n",
    "***Option Pricing Theory**\n",
    "\n",
    "Brownian motion is the benchmark model for the modeling of random pricemovements of financial instruments; the famous Black-Scholes-Mertonoption pricing formula uses a geometric Brownian motion as the model fora stockâ€™s random price fluctuations over time, leading to log-normallydistributed prices and normally distributed returns.\n",
    "\n",
    "\n",
    "The Geometric Brownian Motion is a stochastic process used in financial modelling.\n",
    "\n",
    "Log returns are normally distributed:\n",
    "$\\log \\frac{S_t}{S_s} = -\\log S_t - \\log S_s$ where $0 < s < t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0250f25c6e8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mscr_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpardir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'src'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscr_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYFinanceDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'loader'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "from pylab import mpl, plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "np.random.seed(100)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "scr_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(scr_dir)\n",
    "from loader.load import YFinanceDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a function to generate \n",
    "## a Monte Carlo simulated geometric Brownian Motion\n",
    "def gen_paths(s0, r, sigma, T, M, I):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    s0: (float) initial stock/index value\n",
    "    r: (float) constant short rate\n",
    "    sigma: (float) constant volatility\n",
    "    T: (float) final time horizon\n",
    "    M: (int) number of time steps/intervals\n",
    "    I: (int) number of paths to be simulated\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    paths: ndarray, shape (M + 1, I) simulated paths\n",
    "    \"\"\"\n",
    "    dt = T/M\n",
    "    paths = np.zeros((M + 1, I))\n",
    "    paths[0] = s0\n",
    "    for t in range(1, M + 1):\n",
    "        result = np.random.standard_normal(I)\n",
    "        result = (result - result.mean())/result.std()\n",
    "        paths[t] = paths[t - 1] * np.exp((r - 0.5 * sigma ** 2) * dt + sigma * math.sqrt(dt) * result)\n",
    "    return paths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = 100.\n",
    "r = 0.05\n",
    "sigma = 0.2\n",
    "T = 1.0\n",
    "M = 50\n",
    "I = 250000\n",
    "np.random.seed(1000)\n",
    "paths = gen_paths(s0, r, sigma, T, M, I)\n",
    "init_s = s0 * math.exp(r * T)\n",
    "last_s = paths[-1].mean()\n",
    "print(init_s)\n",
    "print(last_s)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(paths[:, :10])\n",
    "plt.xlabel('time steps')\n",
    "plt.ylabel('index level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[:, 0].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_returns = np.log(paths[1:]/paths[:-1])\n",
    "log_returns[:, 0].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(array):\n",
    "    sta = scs.describe(array)\n",
    "    print('{:14s} {:15s}'.format('statistic', 'value'))\n",
    "    print(30 * '-')\n",
    "    print('{:14s} {:15.5f}'.format('size', sta[0]))\n",
    "    print('{:14s} {:15.5f}'.format('min', np.min(sta[1][0])))\n",
    "    print('{:14s} {:15.5f}'.format('max', np.max(sta[1][1])))\n",
    "    print('{:14s} {:15.5f}'.format('mean', np.mean(sta[2])))\n",
    "    print('{:14s} {:15.5f}'.format('std', np.sqrt(sta[3])))\n",
    "    print('{:14s} {:15.5f}'.format('skew', sta[4]))\n",
    "    print('{:14s} {:15.5f}'.format('kurtosis', sta[5]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_statistics(log_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual test of normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(log_returns.flatten(), bins=70, \n",
    "#          normed=True,\n",
    "         label='frequency', color='b')\n",
    "plt.xlabel('log return')\n",
    "plt.ylabel('frequency')\n",
    "x = np.linspace(plt.axis()[0], plt.axis()[1])\n",
    "plt.plot(x, scs.norm.pdf(x, loc=r/M, \n",
    "                         scale=sigma/np.sqrt(M)), 'r', \n",
    "         lw=2.0, label='pdf')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test by quantile quantile graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sm.qqplot(log_returns.flatten()[::500], line='s')\n",
    "plt.xlabel('theoretical quantiles')\n",
    "plt.ylabel('sample quantiles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tests\n",
    "* skewness: value near 0\n",
    "* kurtosis test: value near 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality_tests(arr):\n",
    "    ''' Tests for normality distribution of given data set.         \n",
    "    Parameters            \n",
    "    ==========             \n",
    "    array: ndarray                 \n",
    "    object to generate statistics on             \n",
    "    '''\n",
    "    print('Skew of data set  %14.3f' % scs.skew(arr))\n",
    "    print('Skew test p-value %14.3f' % scs.skewtest(arr)[1])\n",
    "    print('Kurtosis of data set  %14.3f' % scs.kurtosis(arr))\n",
    "    print('Kurtosis test p-value %14.3f' % scs.kurtosistest(arr)[1])\n",
    "    print('Norm test p-value %14.3f' % scs.normaltest(arr)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if p-value > 0.5 then normal distributed\n",
    "\n",
    "normality_tests(log_returns.flatten()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "ax1.hist(paths[-1],bins=30)\n",
    "ax1.set_xlabel('index level')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.set_title('regular data')\n",
    "ax2.hist(np.log(paths[-1]),bins=30)\n",
    "ax2.set_xlabel('log index level')\n",
    "ax2.set_title('log-data');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_tests(np.log(paths[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "log_data=np.log(paths[-1])\n",
    "plt.hist(log_data, bins=70, label='observed', color='b')\n",
    "plt.xlabel('index levels')\n",
    "plt.ylabel('frequency')\n",
    "x=np.linspace(plt.axis()[0],plt.axis()[1])\n",
    "plt.plot(x,scs.norm.pdf(\n",
    "    x,log_data.mean(),log_data.std()),'r',lw=2.0, label='pdf')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqplot(log_data):\n",
    "    sm.qqplot(log_data, line='s')\n",
    "    plt.xlabel('theoretical quantiles')\n",
    "    plt.ylabel('sample quantiles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(log_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = YFinanceDataset().get_multiple_tickers(\n",
    "     ticker_names=[\n",
    "         'MSFT', \n",
    "         'IBM',\n",
    "         'KO', \n",
    "         'AAPL', \n",
    "         'AMZN', \n",
    "         'GOOG', \n",
    "         'NVDA'\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data/data.iloc[0] * 100).plot(figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_returns = np.log(data/data.shift(1))\n",
    "log_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_returns.hist(bins=50, figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in data.columns:\n",
    "    print('\\nResults for symbol {}'.format(sym))\n",
    "    print(30*'-')\n",
    "    log_data=np.array(log_returns[sym].dropna())\n",
    "    normality_tests(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(log_returns['AAPL_Close'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(log_returns['GOOG_Close'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization\n",
    "The portfolio weights sum to one:\n",
    "\n",
    "$\\sum_{i = 1}^{n}w_i = 1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noa = data.shape[1]  # (1000, 10)\n",
    "rets = np.log(data/data.shift(1))\n",
    "rets.hist(bins=40, figsize=(10, 8));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.mean() * 252 # annualized returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.cov() * 252 # annualized covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.random(noa)\n",
    "weights /= np.sum(weights)\n",
    "print('weights:', weights)\n",
    "print()\n",
    "print('weights sum:', weights.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula for expected return of a portfolio:\n",
    "\n",
    "$\\mu_p = E\\big(\\sum_I w_i r_i \\big) = \\sum_I w_i \\mu_i$\n",
    "\n",
    "use linearity of expectation operator.\n",
    "\n",
    "Expected portfolio variance is given by:\n",
    "\n",
    "the covariance is\n",
    "\n",
    "$\\sigma_{ij} = E(r_i - \\mu_i)(r_j - \\mu_j)$\n",
    "\n",
    "from this we get the variance\n",
    "\n",
    "$\\sigma ^2 = E((r_i - \\mu_i)^2) = \\sum_{i\\in{I}}\\sum_{j\\in{I}}w_iw_j\\sigma_{ij} = w^T\\Sigma w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(rets.mean() * weights) * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(weights.T, np.dot(rets.cov() * 252, weights)) # variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.dot(weights.T,np.dot(rets.cov() * 252,weights))) # volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_ret(weights, rets):\n",
    "    return np.sum(rets.mean() * weights) * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_vol(weights):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prets=[]\n",
    "pvols=[]\n",
    "for p in range(2500):\n",
    "    weights = np.random.random(noa)\n",
    "    weights/=np.sum(weights)\n",
    "    prets.append(port_ret(weights))\n",
    "    pvols.append(port_vol(weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prets = np.array(prets)\n",
    "pvols = np.array(pvols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpe Ratio:\n",
    "\n",
    "$SR = \\frac{\\mu_p - r_f}{\\sigma_p}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.scatter(pvols,prets,c=prets/pvols,marker='o',cmap='coolwarm')\n",
    "plt.xlabel('expected volatility')\n",
    "plt.ylabel('expected return')\n",
    "plt.colorbar(label='Sharpe ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal portfolios\n",
    "The optimal portfolio is found by minimizing with respect to the negative of the Sharpe Ratio. The weights are constrained to be between 0 and 1 and add up to 1.\n",
    "\n",
    "### Minimize \n",
    "The minimize is part of the optimize module in scipy: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_func_sharpe(weights):\n",
    "    return -port_ret(weights)/port_vol(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type':'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bnds = tuple((0, 1) for x in range(noa))\n",
    "eweights = np.array(noa * [1./noa])\n",
    "eweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_func_sharpe(eweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "opts=sco.minimize(min_func_sharpe,\n",
    "                  eweights,method='SLSQP',\n",
    "                  bounds=bnds,\n",
    "                  constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts['x'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_ret(opts['x']).round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_vol(opts['x']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_ret(opts['x'])/port_vol(opts['x']) # sharpe ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minimization of volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optv = sco.minimize(port_vol,eweights,\n",
    "                    method='SLSQP',\n",
    "                    bounds=bnds,\n",
    "                    constraints=cons)\n",
    "optv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array([0.18576914, 0.18558958, 0.18524021, 0.18638385, 0.18620184])).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optv['x'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_vol(optv['x']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_ret(optv['x']).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(port_ret(optv['x'])/port_vol(optv['x'])).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_ret(optv['x'])/port_vol(optv['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient frontier\n",
    "Fix a target return level and derive for each such level those portfolio weights that lead to the minimum volatility value. Because when iterating over different target return levels one condition for the minimization changes. That is why we update the dictionary of constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq', 'fun': lambda x: port_ret(x) - tret},\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bnds = tuple((0, 1) for x in weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "trets = np.linspace(0.175, 0.3, 50)\n",
    "tvols = []\n",
    "for tret in trets:\n",
    "    res = sco.minimize(\n",
    "        port_vol,\n",
    "        eweights,\n",
    "        method='SLSQP',\n",
    "        bounds=bnds,\n",
    "        constraints=cons\n",
    "    )\n",
    "    tvols.append(res['fun'])\n",
    "tvols = np.array(tvols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(pvols,\n",
    "            prets, c=prets/pvols, marker='.',\n",
    "            alpha=0.8, cmap='coolwarm')\n",
    "plt.plot(tvols, trets, 'b', lw=4.0)\n",
    "plt.plot(port_vol(opts['x']), port_ret(opts['x']),'y*', markersize=15.0)\n",
    "plt.plot(port_vol(optv['x']), port_ret(optv['x']),'r*', markersize=15.0)\n",
    "plt.xlabel('expected volatility')\n",
    "plt.ylabel('expected return')\n",
    "plt.colorbar(label='Sharpe ratio');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
